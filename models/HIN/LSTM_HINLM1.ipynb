{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbug2eZ-7iJR",
        "outputId": "0cd1a1d9-f6fd-4e65-e69a-8afcfc5bce52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oi9eRNJ_Ajjw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ot-EjAaqAjsd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6-VvejfPAj0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WM6FviX-Aj9J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "imM0a5LJAkGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eP2lmoneAkOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "54sdJdllAkW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2wS5M8bdAkgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3EHHo5LMAkpg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6TI9047RAkzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1QTx2po3Ak8Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, LayerNormalization, Conv2D, MaxPooling2D, Input, MultiHeadAttention, Layer, Flatten, Reshape, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Custom Transformer Block\n",
        "class TransformerBlock(Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = Sequential([Dense(ff_dim, activation='gelu'), Dense(embed_dim)])\n",
        "        self.layernorm1 = LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = Dropout(rate)\n",
        "        self.dropout2 = Dropout(rate)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "# Sample data\n",
        "text = \"Hello world. This is a sample text for language modeling.\"\n",
        "\n",
        "# Data augmentation: Adding more variations of the sample text\n",
        "augmented_texts = [\n",
        "    \"Hello world! This is a sample text for language modeling.\",\n",
        "    \"Hi world. This is an example text for modeling languages.\",\n",
        "    \"Greetings, world. This text serves as a sample for language modeling.\",\n",
        "    \"Hey world! Here's a sample text for language modeling purposes.\",\n",
        "    \"Hello universe. This is a test text for language modeling.\",\n",
        "]\n",
        "\n",
        "# Combine original and augmented texts\n",
        "all_texts = [text] + augmented_texts\n",
        "\n",
        "# Tokenize the text\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='<OOV>')\n",
        "tokenizer.fit_on_texts(all_texts)\n",
        "sequences = tokenizer.texts_to_sequences(all_texts)\n",
        "\n",
        "# Save the tokenizer to a file in Google Drive\n",
        "tokenizer_path = '/content/drive/MyDrive/converted_models/tokenizer.pickle'\n",
        "with open(tokenizer_path, 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Prepare the dataset\n",
        "seq_length = 10  # Number of previous tokens to consider\n",
        "\n",
        "# Generate sequences\n",
        "dataset = []\n",
        "for seq in sequences:\n",
        "    for i in range(seq_length, len(seq)):\n",
        "        dataset.append(seq[i-seq_length:i])\n",
        "\n",
        "dataset = np.array(dataset)\n",
        "\n",
        "if dataset.size == 0:\n",
        "    raise ValueError(\"The dataset is empty. Please check the sequence length and the text data.\")\n",
        "\n",
        "X, y = dataset[:, :-1], dataset[:, -1]\n",
        "\n",
        "# Ensure X has shape (None, 9)\n",
        "print(f\"Shape of X: {X.shape}\")\n",
        "print(f\"Shape of y: {y.shape}\")\n",
        "\n",
        "# Adjust input shape to match the expected shape\n",
        "inputs = Input(shape=(seq_length-1,))  # seq_length-1 because we're predicting the next token\n",
        "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=seq_length-1)(inputs)\n",
        "transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)(embedding_layer)\n",
        "\n",
        "# Debug: Print shape after transformer block\n",
        "print(f\"Shape after transformer block: {transformer_block.shape}\")\n",
        "\n",
        "reshape_layer = Reshape((seq_length-1, embed_dim, 1))(transformer_block)\n",
        "\n",
        "# Debug: Print shape after reshape for Conv2D\n",
        "print(f\"Shape after reshape for Conv2D: {reshape_layer.shape}\")\n",
        "\n",
        "conv_layer = Conv2D(64, (3, 3), activation='relu', padding='same')(reshape_layer)\n",
        "pool_layer = MaxPooling2D(pool_size=(2, 2))(conv_layer)\n",
        "flatten_layer = Flatten()(pool_layer)\n",
        "\n",
        "# Debug: Print shape after flattening\n",
        "print(f\"Shape after flattening: {flatten_layer.shape}\")\n",
        "\n",
        "# Adjust the reshaping to ensure correct input shape for LSTM\n",
        "new_shape = (flatten_layer.shape[1] // embed_dim, embed_dim)\n",
        "lstm_input = Reshape(new_shape)(flatten_layer)\n",
        "\n",
        "# Debug: Print shape before LSTM\n",
        "print(f\"Shape before LSTM: {lstm_input.shape}\")\n",
        "\n",
        "lstm_layer = LSTM(lstm_units, return_sequences=True)(lstm_input)\n",
        "\n",
        "# Debug: Print shape after first LSTM layer\n",
        "print(f\"Shape after first LSTM layer: {lstm_layer.shape}\")\n",
        "\n",
        "lstm_layer = LSTM(50)(lstm_layer)\n",
        "\n",
        "# Debug: Print shape after second LSTM layer\n",
        "print(f\"Shape after second LSTM layer: {lstm_layer.shape}\")\n",
        "\n",
        "concat_layer = Concatenate()([flatten_layer, lstm_layer])\n",
        "outputs = Dense(vocab_size, activation='softmax')(concat_layer)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=3e-4), metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=50, verbose=2)  # Increase epochs for better training\n",
        "\n",
        "# Save the trained model\n",
        "model.save('/content/drive/MyDrive/converted_models/HINAI_upgraded_with_transformer.h5')\n",
        "\n",
        "# Load the trained model and tokenizer for text generation\n",
        "model = load_model('/content/drive/MyDrive/converted_models/HINAI_upgraded_with_transformer.h5', custom_objects={'TransformerBlock': TransformerBlock})\n",
        "\n",
        "with open(tokenizer_path, 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "def generate_text(seed_text, next_words=50):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        if len(token_list) > seq_length - 1:\n",
        "            token_list = token_list[-(seq_length-1):]  # Truncate sequences longer than seq_length-1\n",
        "        token_list = np.pad(token_list, (seq_length-1-len(token_list), 0), 'constant')\n",
        "        token_list = np.array([token_list])\n",
        "        predicted = model.predict(token_list, verbose=0)\n",
        "        predicted_word_index = np.argmax(predicted, axis=-1)[0]\n",
        "        output_word = tokenizer.index_word.get(predicted_word_index, '<OOV>')\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Test the model\n",
        "seed_text = \"Hello world\"\n",
        "generated_text = generate_text(seed_text, next_words=20)\n",
        "print(generated_text)\n",
        "\"\"\"\n",
        "\n",
        "# Hyperparameter tuning (manual approach)\n",
        "for embed_dim in [64, 128]:\n",
        "    for num_heads in [4, 8]:\n",
        "        for ff_dim in [64, 128]:\n",
        "            for lstm_units in [50, 100]:\n",
        "                print(f\"Training with embed_dim={embed_dim}, num_heads={num_heads}, ff_dim={ff_dim}, lstm_units={lstm_units}\")\n",
        "                inputs = Input(shape=(seq_length-1,))\n",
        "                embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=seq_length-1)(inputs)\n",
        "                transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)(embedding_layer)\n",
        "                reshape_layer = Reshape((seq_length-1, embed_dim, 1))(transformer_block)\n",
        "                conv_layer = Conv2D(64, (3, 3), activation='relu', padding='same')(reshape_layer)\n",
        "                pool_layer = MaxPooling2D(pool_size=(2, 2))(conv_layer)\n",
        "                flatten_layer = Flatten()(pool_layer)\n",
        "                lstm_input = Reshape((flatten_layer.shape[1] // embed_dim, embed_dim))(flatten_layer)\n",
        "                lstm_layer = LST\n",
        "                \"\"\"\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l7_Va9oVAlEe",
        "outputId": "ade6168a-e245-4a40-c5a1-3cbc6be75726"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Shape of X: (1, 9)\n",
            "Shape of y: (1,)\n",
            "Shape after transformer block: (None, 9, 64)\n",
            "Shape after reshape for Conv2D: (None, 9, 64, 1)\n",
            "Shape after flattening: (None, 8192)\n",
            "Shape before LSTM: (None, 128, 64)\n",
            "Shape after first LSTM layer: (None, 128, 100)\n",
            "Shape after second LSTM layer: (None, 50)\n",
            "Epoch 1/50\n",
            "1/1 - 6s - loss: 3.2397 - accuracy: 0.0000e+00 - 6s/epoch - 6s/step\n",
            "Epoch 2/50\n",
            "1/1 - 0s - loss: 2.2332 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 3/50\n",
            "1/1 - 0s - loss: 1.4218 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 4/50\n",
            "1/1 - 0s - loss: 0.7734 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 5/50\n",
            "1/1 - 0s - loss: 0.4083 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 6/50\n",
            "1/1 - 0s - loss: 0.1682 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 7/50\n",
            "1/1 - 0s - loss: 0.0723 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 8/50\n",
            "1/1 - 0s - loss: 0.0366 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 9/50\n",
            "1/1 - 0s - loss: 0.0205 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 10/50\n",
            "1/1 - 0s - loss: 0.0103 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 11/50\n",
            "1/1 - 0s - loss: 0.0056 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 12/50\n",
            "1/1 - 0s - loss: 0.0040 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 13/50\n",
            "1/1 - 0s - loss: 0.0029 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 14/50\n",
            "1/1 - 0s - loss: 0.0017 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 15/50\n",
            "1/1 - 0s - loss: 0.0012 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 16/50\n",
            "1/1 - 0s - loss: 8.9808e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 17/50\n",
            "1/1 - 0s - loss: 7.1393e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 18/50\n",
            "1/1 - 0s - loss: 5.0091e-04 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 19/50\n",
            "1/1 - 0s - loss: 3.8795e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 20/50\n",
            "1/1 - 0s - loss: 3.1955e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 21/50\n",
            "1/1 - 0s - loss: 2.5555e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 22/50\n",
            "1/1 - 0s - loss: 2.1586e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 23/50\n",
            "1/1 - 0s - loss: 1.7796e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 24/50\n",
            "1/1 - 0s - loss: 1.8130e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 25/50\n",
            "1/1 - 0s - loss: 1.2635e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 26/50\n",
            "1/1 - 0s - loss: 1.2027e-04 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 27/50\n",
            "1/1 - 0s - loss: 1.3517e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 28/50\n",
            "1/1 - 0s - loss: 1.0514e-04 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 29/50\n",
            "1/1 - 0s - loss: 8.8330e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 30/50\n",
            "1/1 - 0s - loss: 8.3920e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 31/50\n",
            "1/1 - 0s - loss: 8.0701e-05 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 32/50\n",
            "1/1 - 0s - loss: 7.9986e-05 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 33/50\n",
            "1/1 - 0s - loss: 7.0569e-05 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 34/50\n",
            "1/1 - 0s - loss: 6.8066e-05 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 35/50\n",
            "1/1 - 0s - loss: 6.5563e-05 - accuracy: 1.0000 - 22ms/epoch - 22ms/step\n",
            "Epoch 36/50\n",
            "1/1 - 0s - loss: 6.5563e-05 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 37/50\n",
            "1/1 - 0s - loss: 5.9960e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 38/50\n",
            "1/1 - 0s - loss: 5.4239e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 39/50\n",
            "1/1 - 0s - loss: 5.3166e-05 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 40/50\n",
            "1/1 - 0s - loss: 5.5788e-05 - accuracy: 1.0000 - 21ms/epoch - 21ms/step\n",
            "Epoch 41/50\n",
            "1/1 - 0s - loss: 4.3749e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 42/50\n",
            "1/1 - 0s - loss: 5.0305e-05 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 43/50\n",
            "1/1 - 0s - loss: 4.8040e-05 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 44/50\n",
            "1/1 - 0s - loss: 4.2557e-05 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 45/50\n",
            "1/1 - 0s - loss: 4.4464e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 46/50\n",
            "1/1 - 0s - loss: 4.5895e-05 - accuracy: 1.0000 - 20ms/epoch - 20ms/step\n",
            "Epoch 47/50\n",
            "1/1 - 0s - loss: 4.6371e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 48/50\n",
            "1/1 - 0s - loss: 4.4106e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Epoch 49/50\n",
            "1/1 - 0s - loss: 4.4583e-05 - accuracy: 1.0000 - 18ms/epoch - 18ms/step\n",
            "Epoch 50/50\n",
            "1/1 - 0s - loss: 4.1961e-05 - accuracy: 1.0000 - 19ms/epoch - 19ms/step\n",
            "Hello world language language language language language language language language language language language language language language language language language language language language\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\n# Hyperparameter tuning (manual approach)\\nfor embed_dim in [64, 128]:\\n    for num_heads in [4, 8]:\\n        for ff_dim in [64, 128]:\\n            for lstm_units in [50, 100]:\\n                print(f\"Training with embed_dim={embed_dim}, num_heads={num_heads}, ff_dim={ff_dim}, lstm_units={lstm_units}\")\\n                inputs = Input(shape=(seq_length-1,))\\n                embedding_layer = Embedding(input_dim=vocab_size, output_dim=embed_dim, input_length=seq_length-1)(inputs)\\n                transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)(embedding_layer)\\n                reshape_layer = Reshape((seq_length-1, embed_dim, 1))(transformer_block)\\n                conv_layer = Conv2D(64, (3, 3), activation=\\'relu\\', padding=\\'same\\')(reshape_layer)\\n                pool_layer = MaxPooling2D(pool_size=(2, 2))(conv_layer)\\n                flatten_layer = Flatten()(pool_layer)\\n                lstm_input = Reshape((flatten_layer.shape[1] // embed_dim, embed_dim))(flatten_layer)\\n                lstm_layer = LST\\n                '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g1kbxFB2BVUz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}