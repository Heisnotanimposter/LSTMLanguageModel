{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "YJaO1gS0iV9p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b217ef5c-c3ae-49c4-8fc8-a6cab7fc9a4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKGBDsWwiOyS",
        "outputId": "167bed13-ce4a-4d72-d0ec-ee24a6dbcd76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "import pickle\n",
        "\n",
        "# Mount Google Drive\n",
        "#drive.mount('/content/drive')\n",
        "\n",
        "# Load the TFLite model and allocate tensors\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/merged_model/HINAI.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Load the tokenizer from Google Drive\n",
        "with open('/content/drive/MyDrive/merged_model/tokenizer.pickle', 'rb') as handle:\n",
        "    tokenizer = pickle.load(handle)\n",
        "\n",
        "# Sample input text\n",
        "sample_text = \"Hello world\"\n",
        "\n",
        "# Tokenize the input text\n",
        "input_sequence = tokenizer.texts_to_sequences([sample_text])\n",
        "input_sequence = np.array(input_sequence, dtype=np.float32)\n",
        "\n",
        "# Ensure the input is the correct shape (batch_size, input_length)\n",
        "input_sequence = np.pad(input_sequence, [(0, 0), (0, input_details[0]['shape'][1] - len(input_sequence[0]))], mode='constant')\n",
        "\n",
        "# Set the tensor to point to the input data to be inferred\n",
        "interpreter.set_tensor(input_details[0]['index'], input_sequence)\n",
        "\n",
        "# Run the inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the output tensor\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# Convert the output indices to words\n",
        "predicted_indices = np.argmax(output_data, axis=-1)\n",
        "predicted_words = [tokenizer.index_word[index] for index in predicted_indices if index in tokenizer.index_word]\n",
        "\n",
        "# Join the words to form the output sentence\n",
        "predicted_sentence = ' '.join(predicted_words)\n",
        "print(predicted_sentence)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input sequence:\", input_sequence)"
      ],
      "metadata": {
        "id": "R2cu9ej4iVc_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32db7af0-65f2-43ee-d62c-8ffaa79b0ea5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input sequence: [[1. 2. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the tensor to point to the input data to be inferred\n",
        "interpreter.set_tensor(input_details[0]['index'], input_sequence)\n",
        "# Run the inference\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the output tensor\n",
        "output_data = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "# Debug: Print raw output data\n",
        "print(\"Raw output data:\", output_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AkbxS_Nl1wj",
        "outputId": "1997404a-8c9c-4a10-f050-e68571abcf7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output data: [[1.8598988e-04 4.9915124e-04 2.2658885e-04 2.0716243e-04 9.4442153e-01\n",
            "  4.6993561e-02 1.5727829e-03 4.3988253e-05 1.5473562e-04 1.5924327e-04\n",
            "  5.5352878e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Tokenizer word index:\", tokenizer.word_index)"
      ],
      "metadata": {
        "id": "5JypAyEliVEf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d94992a4-681b-4f4a-8d34-b5a0a4900523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer word index: {'hello': 1, 'world': 2, 'this': 3, 'is': 4, 'a': 5, 'sample': 6, 'text': 7, 'for': 8, 'language': 9, 'modeling': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input shape:\", input_details[0]['shape'])\n",
        "print(\"Output shape:\", output_details[0]['shape'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5DmUoU7lkBN",
        "outputId": "c00cfa23-45ad-4a70-e17e-aa3dbe8eae2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input shape: [1 3]\n",
            "Output shape: [ 1 11]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Raw output data:\", output_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2hbZaHUlnUJ",
        "outputId": "b7f0bd5a-2555-4ee7-b674-424306c79290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw output data: [[1.8598988e-04 4.9915124e-04 2.2658885e-04 2.0716243e-04 9.4442153e-01\n",
            "  4.6993561e-02 1.5727829e-03 4.3988253e-05 1.5473562e-04 1.5924327e-04\n",
            "  5.5352878e-03]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the output indices to words\n",
        "predicted_indices = np.argmax(output_data, axis=-1)\n",
        "predicted_words = [tokenizer.index_word[index] for index in predicted_indices if index in tokenizer.index_word]\n",
        "\n",
        "# Join the words to form the output sentence\n",
        "predicted_sentence = ' '.join(predicted_words)\n",
        "print(predicted_sentence)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Rv6Xz0mlor3",
        "outputId": "4abe68cb-119a-479d-a560-1d6632cb11a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TUti03Vrl7zx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}